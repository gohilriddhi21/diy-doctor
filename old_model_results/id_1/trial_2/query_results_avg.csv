query_llm,judge_llm,faithfulness_avg,relevancy_avg,avg_response_time
meta-llama/llama-3.2-3b-instruct,meta-llama/llama-3.2-3b-instruct,0.7000,0.7000,3.6551
meta-llama/llama-3.2-3b-instruct,mistralai/mistral-7b-instruct,0.2000,0.9000,2.4574
meta-llama/llama-3.2-3b-instruct,qwen/qwen-turbo,0.0000,0.8000,3.2672
mistralai/mistral-7b-instruct,meta-llama/llama-3.2-3b-instruct,0.9000,0.7000,5.8300
mistralai/mistral-7b-instruct,mistralai/mistral-7b-instruct,0.8000,1.0000,3.4542
mistralai/mistral-7b-instruct,qwen/qwen-turbo,0.2000,0.9000,4.7878
qwen/qwen-turbo,meta-llama/llama-3.2-3b-instruct,0.8000,0.4000,5.9857
qwen/qwen-turbo,mistralai/mistral-7b-instruct,0.7000,1.0000,3.5663
qwen/qwen-turbo,qwen/qwen-turbo,0.4000,1.0000,4.6327
