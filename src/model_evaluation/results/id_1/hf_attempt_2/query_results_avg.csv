query_llm,judge_llm,faithfulness_avg,relevancy_avg,avg_response_time
aaditya/Llama3-OpenBioLLM-8B,Henrychur/MMed-Llama-3-8B,0.9000,0.5000,122.5662
aaditya/Llama3-OpenBioLLM-8B,meta-llama/llama-3.2-3b-instruct,0.8000,0.6000,10.9222
aaditya/Llama3-OpenBioLLM-8B,mistralai/mistral-7b-instruct,0.5000,0.8000,8.2320
aaditya/Llama3-OpenBioLLM-8B,qwen/qwen-turbo,0.4000,0.8000,9.1970
aaditya/Llama3-OpenBioLLM-8B,bigcode/starcoder2-7b,0.9000,0.9000,181.2301
Henrychur/MMed-Llama-3-8B,aaditya/Llama3-OpenBioLLM-8B,0.0000,0.1000,109.6916
Henrychur/MMed-Llama-3-8B,meta-llama/llama-3.2-3b-instruct,0.6000,0.7000,62.2845
Henrychur/MMed-Llama-3-8B,mistralai/mistral-7b-instruct,0.3000,0.8000,62.7831
Henrychur/MMed-Llama-3-8B,qwen/qwen-turbo,0.5000,0.4000,63.5988
Henrychur/MMed-Llama-3-8B,bigcode/starcoder2-7b,0.0000,0.0000,237.7000
meta-llama/llama-3.2-3b-instruct,aaditya/Llama3-OpenBioLLM-8B,0.6000,0.9000,18.1564
meta-llama/llama-3.2-3b-instruct,Henrychur/MMed-Llama-3-8B,0.0000,0.0000,116.6809
meta-llama/llama-3.2-3b-instruct,mistralai/mistral-7b-instruct,0.2000,0.9000,3.7512
meta-llama/llama-3.2-3b-instruct,qwen/qwen-turbo,0.0000,0.9000,4.8355
meta-llama/llama-3.2-3b-instruct,bigcode/starcoder2-7b,0.8000,0.3000,169.3984
mistralai/mistral-7b-instruct,aaditya/Llama3-OpenBioLLM-8B,0.5000,0.5000,20.2031
mistralai/mistral-7b-instruct,Henrychur/MMed-Llama-3-8B,0.7000,0.7000,122.6018
mistralai/mistral-7b-instruct,meta-llama/llama-3.2-3b-instruct,0.8000,0.3000,5.5959
mistralai/mistral-7b-instruct,qwen/qwen-turbo,0.3000,0.9000,5.1040
mistralai/mistral-7b-instruct,bigcode/starcoder2-7b,1.0000,0.8000,181.6786
qwen/qwen-turbo,aaditya/Llama3-OpenBioLLM-8B,0.7000,0.8000,22.2405
qwen/qwen-turbo,Henrychur/MMed-Llama-3-8B,0.1000,0.0000,117.5705
qwen/qwen-turbo,meta-llama/llama-3.2-3b-instruct,0.8000,0.4000,5.6156
qwen/qwen-turbo,mistralai/mistral-7b-instruct,0.8000,1.0000,4.0947
qwen/qwen-turbo,bigcode/starcoder2-7b,0.8000,0.3000,167.8682
bigcode/starcoder2-7b,aaditya/Llama3-OpenBioLLM-8B,0.1000,0.3000,107.1490
bigcode/starcoder2-7b,Henrychur/MMed-Llama-3-8B,0.0000,0.0000,205.0928
bigcode/starcoder2-7b,meta-llama/llama-3.2-3b-instruct,0.6000,0.6000,83.6204
bigcode/starcoder2-7b,mistralai/mistral-7b-instruct,0.7000,0.8000,84.5701
bigcode/starcoder2-7b,qwen/qwen-turbo,0.3000,0.3000,84.3024
